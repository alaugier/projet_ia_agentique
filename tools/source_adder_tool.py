# tools/source_adder_tool.py
import json
import pandas as pd
import numpy as np
from typing import List, Dict, Optional
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import os
import nltk
from nltk.corpus import stopwords
from smolagents import tool

# Assurez-vous que les stop words sont tÃ©lÃ©chargÃ©s
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

class SourceMatcher:
    """Classe pour matcher les questions avec les sources pertinentes du CSV"""
    
    def __init__(self, csv_path: str = "tools/ai900_content.csv"):
        self.csv_path = csv_path
        self.content_df = None
        self.vectorizer = None
        self.content_vectors = None
        self.is_loaded = False
        self.load_data()
    
    def load_data(self):
        """Charge et prÃ©pare les donnÃ©es du CSV"""
        try:
            # Essayer plusieurs chemins possibles
            possible_paths = [
                self.csv_path,
                os.path.join(os.path.dirname(__file__), "ai900_content.csv"),
                os.path.join(os.getcwd(), "tools", "ai900_content.csv"),
                "ai900_content.csv"
            ]
            
            csv_found = False
            for path in possible_paths:
                if os.path.exists(path):
                    self.csv_path = path
                    csv_found = True
                    print(f"âœ… CSV trouvÃ© Ã  : {path}")
                    break
            
            if not csv_found:
                print(f"âŒ CSV non trouvÃ© dans les chemins : {possible_paths}")
                return
            
            # Charger le CSV
            self.content_df = pd.read_csv(self.csv_path)
            print(f"ğŸ“Š CSV chargÃ© avec {len(self.content_df)} lignes")
            
            # VÃ©rifier les colonnes requises
            required_columns = ['module_name', 'unit_name', 'content', 'source_url']
            missing_columns = [col for col in required_columns if col not in self.content_df.columns]
            
            if missing_columns:
                print(f"âŒ Colonnes manquantes : {missing_columns}")
                print(f"ğŸ“‹ Colonnes disponibles : {list(self.content_df.columns)}")
                return
            
            # Nettoyer les donnÃ©es - filtrer les lignes avec content null
            self.content_df = self.content_df.dropna(subset=['content'])
            print(f"ğŸ§¹ AprÃ¨s nettoyage : {len(self.content_df)} lignes")
            
            if len(self.content_df) == 0:
                print("âŒ Aucune donnÃ©e utilisable aprÃ¨s nettoyage")
                return
            
            # CrÃ©er le texte combinÃ© pour la vectorisation
            self.content_df['combined_text'] = (
                self.content_df['module_name'].astype(str) + " " + 
                self.content_df['unit_name'].astype(str) + " " + 
                self.content_df['content'].astype(str)
            ).str.lower()
            
            # Initialiser le vectorizer
            try:
                french_stopwords = set(stopwords.words('french'))
                english_stopwords = set(stopwords.words('english'))
                combined_stopwords = list(french_stopwords.union(english_stopwords))
            except:
                # Fallback si les stopwords ne sont pas disponibles
                combined_stopwords = ['le', 'de', 'et', 'Ã ', 'un', 'il', 'Ãªtre', 'et', 'en', 'avoir', 'que', 'pour', 'dans', 'ce', 'son', 'une', 'sur', 'avec', 'ne', 'se', 'pas', 'tout', 'plus', 'par', 'grand', 'comme', 'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he', 'in', 'is', 'it', 'its', 'of', 'on', 'that', 'the', 'to', 'was', 'were', 'will', 'with']
            
            self.vectorizer = TfidfVectorizer(
                max_features=3000,
                stop_words=combined_stopwords,
                ngram_range=(1, 3),
                min_df=1,
                max_df=0.85,
                token_pattern=r'\b[a-zA-ZÃ€-Ã¿]{2,}\b'
            )
            
            # Vectoriser le contenu
            self.content_vectors = self.vectorizer.fit_transform(self.content_df['combined_text'])
            print(f"ğŸ”¢ Vectorisation terminÃ©e : {self.content_vectors.shape}")
            
            self.is_loaded = True
            print("âœ… SourceMatcher initialisÃ© avec succÃ¨s")
            
        except Exception as e:
            print(f"âŒ Erreur lors du chargement des donnÃ©es : {e}")
            import traceback
            traceback.print_exc()
            self.is_loaded = False
    
    def find_relevant_sources(self, question_text: str, max_sources: int = 3) -> List[Dict]:
        """Trouve les sources les plus pertinentes pour une question"""
        if not self.is_loaded:
            print("âš ï¸  SourceMatcher non chargÃ©")
            return []
        
        try:
            # PrÃ©parer le texte de la question
            query_text = question_text.lower()
            
            # Vectoriser la question
            query_vector = self.vectorizer.transform([query_text])
            
            # Calculer les similaritÃ©s
            similarities = cosine_similarity(query_vector, self.content_vectors).flatten()
            
            # Obtenir les indices des sources les plus pertinentes
            top_indices = np.argsort(similarities)[::-1][:max_sources * 2]  # Prendre plus pour filtrer
            
            relevant_sources = []
            seen_urls = set()
            
            for idx in top_indices:
                if len(relevant_sources) >= max_sources:
                    break
                
                similarity = similarities[idx]
                if similarity > 0.1:  # Seuil de pertinence
                    row = self.content_df.iloc[idx]
                    source_url = row['source_url']
                    
                    # Ã‰viter les doublons d'URLs
                    if source_url not in seen_urls:
                        relevant_sources.append({
                            'url': source_url,
                            'title': f"{row['module_name']} - {row['unit_name']}",
                            'similarity': float(similarity),
                            'content_preview': row['content'][:200] + "..." if len(row['content']) > 200 else row['content']
                        })
                        seen_urls.add(source_url)
            
            print(f"ğŸ” TrouvÃ© {len(relevant_sources)} sources pour la question")
            return relevant_sources
            
        except Exception as e:
            print(f"âŒ Erreur lors de la recherche de sources : {e}")
            import traceback
            traceback.print_exc()
            return []

@tool
def add_sources_to_quiz_tool(quiz_json: str, max_sources: int = 3) -> str:
    """
    Ajoute des sources pertinentes Ã  chaque question du quiz en utilisant 
    la base de donnÃ©es locale AI-900.
    
    Args:
        quiz_json: JSON du quiz gÃ©nÃ©rÃ©
        max_sources: Nombre maximum de sources par question (dÃ©faut: 3)
    
    Returns:
        JSON du quiz enrichi avec sources
    """
    try:
        print(f"ğŸ”— DÃ©but de l'ajout de sources (max {max_sources} par question)")
        
        # Parser le JSON d'entrÃ©e
        try:
            quiz_data = json.loads(quiz_json)
        except json.JSONDecodeError as e:
            print(f"âŒ Erreur de parsing JSON : {e}")
            return quiz_json  # Retourner le JSON original si erreur
        
        # Extraire les questions selon le format
        if "questions" in quiz_data:
            questions = quiz_data["questions"]
            has_metadata = True
        elif isinstance(quiz_data, list):
            questions = quiz_data
            has_metadata = False
        else:
            print("âŒ Format de quiz non reconnu")
            return quiz_json
        
        if not questions:
            print("âš ï¸  Aucune question trouvÃ©e dans le quiz")
            return quiz_json
        
        print(f"ğŸ“ Traitement de {len(questions)} questions")
        
        # Initialiser le matcher de sources
        source_matcher = SourceMatcher()
        
        if not source_matcher.is_loaded:
            print("âš ï¸  Impossible de charger les sources, retour du quiz original")
            return quiz_json
        
        # Traiter chaque question
        questions_with_sources = []
        total_sources_added = 0
        
        for i, question in enumerate(questions):
            question_copy = question.copy()
            
            # CrÃ©er le texte de recherche (question + explication pour plus de contexte)
            search_text = question.get('question', '')
            explanation = question.get('explanation', '')
            if explanation:
                search_text += " " + explanation
            
            # Trouver les sources pertinentes
            relevant_sources = source_matcher.find_relevant_sources(search_text, max_sources)
            
            if relevant_sources:
                # Ajouter les sources Ã  la question
                question_copy['sources'] = {
                    'urls': [source['url'] for source in relevant_sources],
                    'details': relevant_sources,
                    'count': len(relevant_sources)
                }
                total_sources_added += len(relevant_sources)
                print(f"  âœ… Question {i+1}: {len(relevant_sources)} sources ajoutÃ©es")
            else:
                # MÃªme sans sources, ajouter une structure vide pour la cohÃ©rence
                question_copy['sources'] = {
                    'urls': [],
                    'details': [],
                    'count': 0
                }
                print(f"  âš ï¸  Question {i+1}: Aucune source pertinente trouvÃ©e")
            
            questions_with_sources.append(question_copy)
        
        # Reconstruire le JSON final
        if has_metadata:
            quiz_data["questions"] = questions_with_sources
            # Ajouter des mÃ©tadonnÃ©es sur les sources
            if "quiz_info" not in quiz_data:
                quiz_data["quiz_info"] = {}
            quiz_data["quiz_info"]["sources_added"] = total_sources_added
            quiz_data["quiz_info"]["avg_sources_per_question"] = round(total_sources_added / len(questions), 2) if len(questions) > 0 else 0
            final_result = quiz_data
        else:
            final_result = questions_with_sources
        
        print(f"ğŸ‰ Ajout de sources terminÃ© : {total_sources_added} sources au total")
        
        return json.dumps(final_result, ensure_ascii=False, indent=2)
        
    except Exception as e:
        print(f"âŒ Erreur lors de l'ajout de sources : {e}")
        import traceback
        traceback.print_exc()
        # En cas d'erreur, retourner le quiz original plutÃ´t que d'Ã©chouer
        return quiz_json

@tool
def test_source_matching(question_text: str, max_sources: int = 5) -> str:
    """
    Teste la fonction de matching de sources pour une question donnÃ©e.
    Utile pour dÃ©boguer et optimiser la pertinence des sources.
    
    Args:
        question_text: Texte de la question Ã  tester
        max_sources: Nombre maximum de sources Ã  retourner (dÃ©faut: 5)
    
    Returns:
        RÃ©sultats du matching formatÃ©s
    """
    try:
        print(f"ğŸ§ª Test de matching pour : {question_text[:100]}...")
        
        source_matcher = SourceMatcher()
        
        if not source_matcher.is_loaded:
            return "âŒ SourceMatcher non chargÃ© - vÃ©rifiez le fichier CSV"
        
        sources = source_matcher.find_relevant_sources(question_text, max_sources)
        
        result = f"ğŸ” RÃ©sultats du matching de sources :\n\n"
        result += f"ğŸ“‹ Question testÃ©e : {question_text}\n\n"
        result += f"ğŸ“Š Sources trouvÃ©es : {len(sources)}\n\n"
        
        if sources:
            for i, source in enumerate(sources, 1):
                result += f"{i}. **{source['title']}**\n"
                result += f"   - URL : {source['url']}\n"
                result += f"   - SimilaritÃ© : {source['similarity']:.3f}\n"
                result += f"   - AperÃ§u : {source['content_preview'][:150]}...\n\n"
        else:
            result += "âš ï¸  Aucune source pertinente trouvÃ©e\n"
        
        return result
        
    except Exception as e:
        print(f"âŒ Erreur lors du test : {e}")
        import traceback
        traceback.print_exc()
        return f"âŒ Erreur lors du test : {e}"

# Fonction utilitaire pour vÃ©rifier le CSV
def check_csv_structure(csv_path: str = "tools/ai900_content.csv") -> str:
    """
    VÃ©rifie la structure du CSV et affiche des informations utiles pour le debug
    """
    try:
        # Essayer plusieurs chemins possibles
        possible_paths = [
            csv_path,
            os.path.join(os.path.dirname(__file__), "ai900_content.csv"),
            os.path.join(os.getcwd(), "tools", "ai900_content.csv"),
            "ai900_content.csv"
        ]
        
        csv_found = False
        actual_path = ""
        for path in possible_paths:
            if os.path.exists(path):
                actual_path = path
                csv_found = True
                break
        
        if not csv_found:
            return f"âŒ CSV non trouvÃ© dans les chemins : {possible_paths}"
        
        # Charger et analyser le CSV
        df = pd.read_csv(actual_path)
        
        info = f"âœ… CSV trouvÃ© Ã  : {actual_path}\n"
        info += f"ğŸ“Š Nombre de lignes : {len(df)}\n"
        info += f"ğŸ“‹ Colonnes : {list(df.columns)}\n"
        info += f"ğŸ” AperÃ§u des premiÃ¨re lignes :\n"
        info += str(df.head(2).to_string()) + "\n"
        
        # VÃ©rifier les colonnes requises
        required_columns = ['module_name', 'unit_name', 'content', 'source_url']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            info += f"âŒ Colonnes manquantes : {missing_columns}\n"
        else:
            info += f"âœ… Toutes les colonnes requises sont prÃ©sentes\n"
            
        # VÃ©rifier les valeurs nulles
        null_counts = df[required_columns].isnull().sum()
        info += f"ğŸ” Valeurs nulles par colonne :\n{null_counts}\n"
        
        # Statistiques sur le contenu
        df_clean = df.dropna(subset=['content'])
        info += f"ğŸ“Š Lignes avec contenu valide : {len(df_clean)}\n"
        
        return info
        
    except Exception as e:
        return f"âŒ Erreur lors de la vÃ©rification du CSV : {e}"

if __name__ == "__main__":
    # Test rapide du module
    print("ğŸ§ª Test du module source_adder_tool")
    print(check_csv_structure())
    
    # Test de base
    test_question = "Qu'est-ce que l'intelligence artificielle?"
    print(f"\nğŸ” Test avec la question : {test_question}")
    print(test_source_matching(test_question, 3))