{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba98b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Configuration du navigateur\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.maximize_window()\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "try:\n",
    "    \n",
    "    url = 'https://learn.microsoft.com/fr-fr/credentials/certifications/azure-ai-fundamentals/?practice-assessment-type=certification'\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'article')))\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    article = soup.find('article', class_='card border-color-accent border-left-lg card-horizontal')\n",
    "\n",
    "    if not article:\n",
    "        raise Exception(\"Article non trouvé\")\n",
    "\n",
    "    # Récupérer les liens (ignorer les 2 premiers)\n",
    "    liens = article.find_all('a')[2:]\n",
    "    for lien in liens:\n",
    "        module_name = lien.get_text(strip=True)\n",
    "        href = lien.get('href')\n",
    "        if not href.startswith(\"http\"):\n",
    "            href = \"https://learn.microsoft.com\" + href\n",
    "\n",
    "        print(f\"\\n--- MODULE : {module_name} ---\\nURL : {href}\")\n",
    "        driver.get(href)\n",
    "        time.sleep(4)\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        units_cards = soup.find_all('div', class_='padding-sm padding-bottom-none-tablet')\n",
    "        for card in units_cards:\n",
    "            print(f\"\\n--- CARD ---\")\n",
    "            button = soup.find_all('button', class_='unit-expander')\n",
    "            buttons = driver.find_elements(By.XPATH, \"//button[.//span[text()='Vue d’ensemble']]\")\n",
    "            for i, button in enumerate(buttons):\n",
    "                time.sleep(3)\n",
    "                try:\n",
    "                    aria_expanded = button.get_attribute(\"aria-expanded\")\n",
    "                    if aria_expanded == \"false\":\n",
    "                        print(f\" ➤ Ouverture du bouton Vue d’ensemble #{i+1}\")\n",
    "                        driver.execute_script(\"arguments[0].click();\", button)\n",
    "            \n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"   ⚠️ Erreur lors du clic sur le bouton Vue d’ensemble #{i+1}: {str(e)}\")\n",
    "                \n",
    "            updated_html = driver.page_source\n",
    "            updated_soup = BeautifulSoup(updated_html, 'html.parser')\n",
    "\n",
    "            unit_links = updated_soup.find_all('a', class_='unit-title')\n",
    "            for unit_link in unit_links:\n",
    "                unit_name = unit_link.get_text(strip=True)\n",
    "                unit_href = unit_link['href']\n",
    "                if not unit_href.startswith(\"http\"):\n",
    "                    unit_href = \"https://learn.microsoft.com\" + unit_href\n",
    "\n",
    "                driver.get(unit_href)\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'module-unit-content')))\n",
    "                    unit_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                    content_div = unit_soup.find('div', id='module-unit-content')\n",
    "                    content_text = content_div.get_text(separator=\"\\n\", strip=True) if content_div else \"\"\n",
    "\n",
    "                    data.append({\n",
    "                        'module_name': module_name if 'module_name' in locals() else '',  # Avoid NameError\n",
    "                        'unit_name': unit_name,\n",
    "                        'content': content_text,\n",
    "                        'source_url': unit_href\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur sur l'unité '{unit_name}' ({unit_href}) : {str(e)}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "# Création du DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9239afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a375bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour sauvegarder :\n",
    "df.to_csv(\"modules_units_content.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_scraping_ai900",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
